{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8w8DRjGAHzyG"
   },
   "outputs": [],
   "source": [
    "# Usar keras 2.2.5\n",
    "# conda install -c conda-forge keras=2.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rnLq6p7aHzyK",
    "outputId": "fce14c7d-5a9b-46ef-e885-519055aa8461"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "l6qXmkzsHzyO",
    "outputId": "a77232bb-fe5f-421f-de4f-eeb1098e2b09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0KnibsN1xUk3"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb as dataset\n",
    "#from keras.datasets import reuters as dataset\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvpowIEOHzyT"
   },
   "source": [
    "# Cargamos y analizamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4ra2gF4HzyU",
    "outputId": "3d4bb439-4aa5-4739-8013-f817582c9e26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 3s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\scis1\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\scis1\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# Primer hyperparámetro\n",
    "num_words=30000\n",
    "\n",
    "(training_data, training_targets), (testing_data, testing_targets) = dataset.load_data(num_words=num_words+2)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYWTLfB1xUlI",
    "outputId": "06235617-7413-4b40-ab44-9abe9c1a16f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: [0 1]\n",
      "Number of unique words: 30000\n"
     ]
    }
   ],
   "source": [
    "# Tengo dos categorías: Sentimiento positivo (1) o sentimiento negativo (0)\n",
    "num_categories = len(np.unique(targets))\n",
    "print(\"Categories:\", np.unique(targets))\n",
    "# Tengo num_words palabras únicas en el vocabulario\n",
    "print(\"Number of unique words:\", len(np.unique(np.hstack(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lZ-DUxtxUlT",
    "outputId": "5a1660be-ed31-44a8-9ec6-89d0de4d7973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Review length: 234.75892\n",
      "Standard Deviation: 173\n"
     ]
    }
   ],
   "source": [
    "# Longitudes promedio de los comentarios de las películas\n",
    "length = [len(i) for i in data]\n",
    "print(\"Average Review length:\", np.mean(length))\n",
    "print(\"Standard Deviation:\", round(np.std(length)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGeDrxcRHzya"
   },
   "source": [
    "# Impresión de comentario preprocesado con su etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnT33-acxUlZ",
    "outputId": "e9784e60-758a-447e-ca0c-6a1986988493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n",
      "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n"
     ]
    }
   ],
   "source": [
    "# Imprimo cometario i'esimo con su clasificación de sentimiento\n",
    "i = 1\n",
    "print(\"Label:\", targets[i])\n",
    "# Las comentarios ya están preprocesados\n",
    "print(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GSVq9thIxUlh",
    "outputId": "ccf2a871-68fd-4d7f-95e1-4a64180e1bf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "['fawn:34701', 'tsukino:52006', 'nunnery:52007', 'sonja:16816', 'vani:63951', 'woods:1408', 'spiders:16115', 'hanging:2345', 'woody:2289', 'trawling:52008', \"hold's:52009\", 'comically:11307', 'localized:40830', 'disobeying:30568', \"'royale:52010\", \"harpo's:40831\", 'canet:52011', 'aileen:19313', 'acurately:52012', \"diplomat's:52013\", 'rickman:25242', 'arranged:6746', 'rumbustious:52014', 'familiarness:52015', \"spider':52016\", 'hahahah:68804', \"wood':52017\", 'transvestism:40833', \"hangin':34702\", 'bringing:2338', 'seamier:40834', 'wooded:34703', 'bravora:52018', 'grueling:16817', 'wooden:1636', 'wednesday:16818', \"'prix:52019\", 'altagracia:34704', 'circuitry:52020', 'crotch:11585', 'busybody:57766', \"tart'n'tangy:52021\", 'burgade:14129', 'thrace:52023', \"tom's:11038\", 'snuggles:52025', 'francesco:29114', 'complainers:52027', 'templarios:52125', '272:40835', '273:52028', 'zaniacs:52130', '275:34706', 'consenting:27631', 'snuggled:40836', 'inanimate:15492', 'uality:52030', 'bronte:11926', 'errors:4010', 'dialogs:3230', \"yomada's:52031\", \"madman's:34707\", 'dialoge:30585', 'usenet:52033', 'videodrome:40837', \"kid':26338\", 'pawed:52034', \"'girlfriend':30569\", \"'pleasure:52035\", \"'reloaded':52036\", \"kazakos':40839\", 'rocque:52037', 'mailings:52038', 'brainwashed:11927', 'mcanally:16819', \"tom'':52039\", 'kurupt:25243', 'affiliated:21905', 'babaganoosh:52040', \"noe's:40840\", 'quart:40841', 'kids:359', 'uplifting:5034', 'controversy:7093', 'kida:21906', 'kidd:23379', \"error':52041\", 'neurologist:52042', 'spotty:18510', 'cobblers:30570', 'projection:9878', 'fastforwarding:40842', 'sters:52043', \"eggar's:52044\", 'etherything:52045', 'gateshead:40843', 'airball:34708', 'unsinkable:25244', 'stern:7180', \"cervi's:52046\"]\n"
     ]
    }
   ],
   "source": [
    "# Bajamos diccionario de palabras a indices\n",
    "index = dataset.get_word_index()\n",
    "print([f'{k}:{v}' for k,v in index.items()][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xrmkTbXyHzyf",
    "outputId": "af21dce6-abac-4554-ee14-1e7203f517f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['34701:fawn', '52006:tsukino', '52007:nunnery', '16816:sonja', '63951:vani', '1408:woods', '16115:spiders', '2345:hanging', '2289:woody', '52008:trawling', \"52009:hold's\", '11307:comically', '40830:localized', '30568:disobeying', \"52010:'royale\", \"40831:harpo's\", '52011:canet', '19313:aileen', '52012:acurately', \"52013:diplomat's\", '25242:rickman', '6746:arranged', '52014:rumbustious', '52015:familiarness', \"52016:spider'\", '68804:hahahah', \"52017:wood'\", '40833:transvestism', \"34702:hangin'\", '2338:bringing', '40834:seamier', '34703:wooded', '52018:bravora', '16817:grueling', '1636:wooden', '16818:wednesday', \"52019:'prix\", '34704:altagracia', '52020:circuitry', '11585:crotch', '57766:busybody', \"52021:tart'n'tangy\", '14129:burgade', '52023:thrace', \"11038:tom's\", '52025:snuggles', '29114:francesco', '52027:complainers', '52125:templarios', '40835:272', '52028:273', '52130:zaniacs', '34706:275', '27631:consenting', '40836:snuggled', '15492:inanimate', '52030:uality', '11926:bronte', '4010:errors', '3230:dialogs', \"52031:yomada's\", \"34707:madman's\", '30585:dialoge', '52033:usenet', '40837:videodrome', \"26338:kid'\", '52034:pawed', \"30569:'girlfriend'\", \"52035:'pleasure\", \"52036:'reloaded'\", \"40839:kazakos'\", '52037:rocque', '52038:mailings', '11927:brainwashed', '16819:mcanally', \"52039:tom''\", '25243:kurupt', '21905:affiliated', '52040:babaganoosh', \"40840:noe's\", '40841:quart', '359:kids', '5034:uplifting', '7093:controversy', '21906:kida', '23379:kidd', \"52041:error'\", '52042:neurologist', '18510:spotty', '30570:cobblers', '9878:projection', '40842:fastforwarding', '52043:sters', \"52044:eggar's\", '52045:etherything', '40843:gateshead', '34708:airball', '25244:unsinkable', '7180:stern', \"52046:cervi's\"]\n"
     ]
    }
   ],
   "source": [
    "# Armo diccionario reverso: de indices a palabras\n",
    "reverse_index = dict([(value, key) for (key, value) in index.items()]) \n",
    "print([f'{k}:{v}' for k,v in reverse_index.items()][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lhq6d5MWHzyi",
    "outputId": "9e243541-ba8e-423b-caed-4d3afbf1bb07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
      "\n",
      "# big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal measures the hair is big lots of boobs bounce men wear those cut tee shirts that show off their stomachs sickening that men actually wore them and the music is just # trash that plays over and over again in almost every scene there is trashy music boobs and paramedics taking away bodies and the gym still doesn't close for # all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n"
     ]
    }
   ],
   "source": [
    "decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in data[1]] )\n",
    "print(data[1])\n",
    "print()\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBL_1v2eHzym"
   },
   "source": [
    "# Padding y formateo de data para entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HifepVsJxUlo"
   },
   "outputs": [],
   "source": [
    "# Hyperparametro - Longitud máxima de comentario\n",
    "maxlen=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Tb8Mf33exUlu"
   },
   "outputs": [],
   "source": [
    "data = pad_sequences(data,maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fq-c12e5xUl8",
    "outputId": "343d0482-5531-4de6-812c-cb01468080b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Verificamos que todos tengan longitud 1000\n",
    "print(len(data[0]))\n",
    "print(np.array([len(d) for d in data]).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jXBIUZaNxUmD"
   },
   "outputs": [],
   "source": [
    "data=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Gwma-IqxUmK",
    "outputId": "90b14a6f-d7f4-49bb-81ab-ff81794f36d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bplIZHWNUXo"
   },
   "source": [
    "# Armar una MLP con one-hot encoding para resolver el problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MQ51AMr2Nbok"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oesd0wSV3dh6",
    "outputId": "05d3b69f-8c8c-480b-c2f8-3aa3e35b93f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YV5eg2fDNdtk"
   },
   "outputs": [],
   "source": [
    "# usar maxlen y num_words para calcular la entrada\n",
    "# Utilizar una sola capa\n",
    "salida_densa = 2\n",
    "input_shape = (maxlen,num_words)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10000, input_shape = input_shape, activation = 'relu'))\n",
    "model.add(Dense(10000, activation = 'relu'))\n",
    "\n",
    "\n",
    "## TODO\n",
    "\n",
    "model.add(Dense(salida_densa,  activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXqCIIv6OWe8",
    "outputId": "86ef64f6-187c-4d8f-97d1-87a9d1688c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1000, 10000)       300010000 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000, 10000)       100010000 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000, 2)           20002     \n",
      "=================================================================\n",
      "Total params: 400,040,002\n",
      "Trainable params: 400,040,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-RLYV5QPBEX"
   },
   "source": [
    "## ¿Por que no es viable esta red?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnvzV5wiPKjs"
   },
   "source": [
    "# Armar una MLP usando Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ecjdmUczPIVf"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Flatten, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "OPTlDXslPO0o"
   },
   "outputs": [],
   "source": [
    "# Cantidad de palabras totales contando las reservadas\n",
    "nb_words=num_words+3\n",
    "# Tamano del embedding. Es un hiperparámetro y puede modificarlo\n",
    "embed_dim=32\n",
    "salida_capa_densa = 1\n",
    "dropout=0.2 # Hiperparámetro\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words, embed_dim, input_length=maxlen, trainable=True))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(salida_capa_densa, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTs8XKCLPVqX",
    "outputId": "af305018-bec4-4558-901b-fefa51a1c7fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 1000, 32)          960096    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 960,129\n",
      "Trainable params: 960,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6bygoYSP1PW",
    "outputId": "c2f22ac8-9378-4a42-998d-4963b4f96870"
   },
   "outputs": [],
   "source": [
    "# MODIFIQUE HYPERPARAMS A GUSTO\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AypW8ZrEIgdo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4tv5kkjPuaj",
    "outputId": "c98b7eb4-c992-4411-8574-865e08f0b725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.6789 - accuracy: 0.5985 - val_loss: 0.5773 - val_accuracy: 0.8065\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.5332 - accuracy: 0.8138 - val_loss: 0.4347 - val_accuracy: 0.8542\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 0.4003 - accuracy: 0.8672 - val_loss: 0.3526 - val_accuracy: 0.8807\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 0.3285 - accuracy: 0.8895 - val_loss: 0.3092 - val_accuracy: 0.8892\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 31s 24ms/step - loss: 0.2855 - accuracy: 0.8998 - val_loss: 0.2835 - val_accuracy: 0.8957\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 33s 27ms/step - loss: 0.2534 - accuracy: 0.9095 - val_loss: 0.2722 - val_accuracy: 0.8943\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 33s 26ms/step - loss: 0.2289 - accuracy: 0.9202 - val_loss: 0.2623 - val_accuracy: 0.8972\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 33s 26ms/step - loss: 0.2137 - accuracy: 0.9229 - val_loss: 0.2510 - val_accuracy: 0.9027\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 0.1989 - accuracy: 0.9311 - val_loss: 0.2453 - val_accuracy: 0.9048\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 0.1823 - accuracy: 0.9355 - val_loss: 0.2425 - val_accuracy: 0.9058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2851acd2580>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data,targets,batch_size=32,epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNPXfSxWQRI3"
   },
   "source": [
    "# Armar una CNN\n",
    "Abajo hay un ejemplo de arquitectur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "UDm9X9r5LSTY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words, embed_dim, input_length=maxlen, trainable=True))\n",
    "model.add(Conv1D(64,5, activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(128,5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(salida_capa_densa, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZwz7fXSO5Uy",
    "outputId": "2ea7c4e7-fb9d-4d13-bb4f-9577f0cecae7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 1000, 32)          960096    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 996, 64)           10304     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 498, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 494, 128)          41088     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 500)               64500     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 1,076,489\n",
      "Trainable params: 1,076,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "C8Yi3_A4V5AS"
   },
   "outputs": [],
   "source": [
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# embedding_12 (Embedding)     (None, 1000, 32)          960096    \n",
    "# _________________________________________________________________\n",
    "# conv1d_7 (Conv1D)            (None, 1000, 64)          14400     \n",
    "# _________________________________________________________________\n",
    "# max_pooling1d_4 (MaxPooling1 (None, 500, 64)           0         \n",
    "# _________________________________________________________________\n",
    "# conv1d_8 (Conv1D)            (None, 500, 128)          57472     \n",
    "# _________________________________________________________________\n",
    "# global_max_pooling1d_4 (Glob (None, 128)               0         \n",
    "# _________________________________________________________________\n",
    "# dropout_4 (Dropout)          (None, 128)               0         \n",
    "# _________________________________________________________________\n",
    "# dense_19 (Dense)             (None, 46)                5934      \n",
    "# ================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vS2t0m9LNX6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ssxu2rPVV_d_",
    "outputId": "a545525b-b5f7-4f4b-91d4-1260aff7f6f2"
   },
   "outputs": [],
   "source": [
    "# MODIFIQUE HYPERPARAMS A GUSTO\n",
    "adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AzXyAjAvxUmW",
    "outputId": "a2a628e8-0670-4d5b-fc20-1de5fa786fad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1250/1250 [==============================] - 227s 181ms/step - loss: 0.5000 - accuracy: 0.7197 - val_loss: 0.2607 - val_accuracy: 0.8952\n",
      "Epoch 2/5\n",
      "1250/1250 [==============================] - 234s 187ms/step - loss: 0.1757 - accuracy: 0.9356 - val_loss: 0.2374 - val_accuracy: 0.9039\n",
      "Epoch 3/5\n",
      "1250/1250 [==============================] - 207s 166ms/step - loss: 0.0791 - accuracy: 0.9734 - val_loss: 0.2993 - val_accuracy: 0.8942\n",
      "Epoch 4/5\n",
      "1250/1250 [==============================] - 254s 204ms/step - loss: 0.0407 - accuracy: 0.9853 - val_loss: 0.3794 - val_accuracy: 0.8952\n",
      "Epoch 5/5\n",
      "1250/1250 [==============================] - 161s 128ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.4443 - val_accuracy: 0.8963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28518d3ea60>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data,targets,batch_size=32,epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBZtuDJsM3mK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Trainable Embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
